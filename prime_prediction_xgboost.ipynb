{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b5bfb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gmpy2 as gmp\n",
    "from multiprocess import Pool, cpu_count\n",
    "from hyperopt import hp, fmin, tpe\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e449a090",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Create a dataset of N-bit binary strings. Each string represents an integer labeled 0 (composite) or 1 (prime)\n",
    "#\n",
    "def create_N_bit_labeled_strings(N, chunk_size=1024):\n",
    "    \n",
    "    # data container\n",
    "    data = []\n",
    "    num_cores = cpu_count()\n",
    "\n",
    "    # save data to a CSV file \n",
    "    csv_file = f'binary_data_{N}.csv'\n",
    "\n",
    "    def is_prime(binary_string):\n",
    "        decimal_value = gmp.mpz(binary_string, base=2)\n",
    "        return binary_string, int(gmp.is_prime(decimal_value))\n",
    "\n",
    "    with open(csv_file, \"w\", newline=\"\") as file:\n",
    "\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"BinaryString\", \"Label\"])\n",
    "\n",
    "        # generate binary strings and check primality in chunks\n",
    "        for chunk_start in range(0, 2**N, chunk_size):\n",
    "\n",
    "            print(chunk_start)\n",
    "\n",
    "            chunk_end = min(chunk_start + chunk_size, 2**N)\n",
    "\n",
    "            binary_strings = [format(i, f'0{N}b') for i in range(chunk_start, chunk_end)]\n",
    "\n",
    "            with Pool(num_cores) as pool:\n",
    "                data = pool.map(is_prime, binary_strings)\n",
    "\n",
    "            writer.writerows(data)\n",
    "\n",
    "    print('All data saved to '+csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca273f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Datasets are available for 18 and 24 bit strings\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16f42234",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Testing 18-bit strings first\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d007c4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data using Dask\n",
    "ddf_18 = dd.read_csv('binary_data_18.csv', assume_missing=True, dtype={\"BinaryString\": str, \"Label\": int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a9e0c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23000 primes and 239144 composites out of 262144 numbers in total\n"
     ]
    }
   ],
   "source": [
    "# primes vs composites\n",
    "num_composites = sum(ddf_18['Label'] == 0)\n",
    "num_primes     = sum(ddf_18['Label'] == 1)\n",
    "print(f'{num_primes} primes and {num_composites} composites out of {len(ddf_18)} numbers in total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "648163a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Try some educated guess of a model\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "888ed733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.53302\ttest-auc:0.50892\n",
      "[1]\ttrain-auc:0.53633\ttest-auc:0.50437\n",
      "[2]\ttrain-auc:0.53859\ttest-auc:0.50302\n",
      "[3]\ttrain-auc:0.53961\ttest-auc:0.50128\n",
      "[4]\ttrain-auc:0.54034\ttest-auc:0.50039\n",
      "[5]\ttrain-auc:0.54040\ttest-auc:0.50082\n",
      "[6]\ttrain-auc:0.54076\ttest-auc:0.50130\n",
      "[7]\ttrain-auc:0.54107\ttest-auc:0.49986\n",
      "[8]\ttrain-auc:0.54149\ttest-auc:0.49930\n",
      "[9]\ttrain-auc:0.54167\ttest-auc:0.49867\n"
     ]
    }
   ],
   "source": [
    "# train / test split\n",
    "X_train, X_test = ddf_18.random_split([0.8, 0.2], random_state=42)\n",
    "\n",
    "# convert Dask dataframes to DMatrix XGBoost format\n",
    "dtrain = xgb.DMatrix(X_train.drop(columns=['Label']), X_train['Label'])\n",
    "dtest = xgb.DMatrix(X_test.drop(columns=['Label']), X_test['Label'])\n",
    "\n",
    "# choose XGBoost hyperparameters\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'scale_pos_weight': num_composites / num_primes,\n",
    "    'eval_metric': 'auc',  # evaluation metric\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'max_depth': 10,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 1,\n",
    "    'learning_rate': 0.05,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "# train model\n",
    "model = xgb.train(params, dtrain, evals=[(dtrain, 'train'), (dtest, 'test')], verbose_eval=True)\n",
    "\n",
    "# make predictions \n",
    "y_pred_prob = model.predict(dtest)\n",
    "\n",
    "# convert probabilities to binary labels\n",
    "threshold = y_pred_prob.mean()\n",
    "y_pred = [1 if pred >= threshold else 0 for pred in y_pred_prob]\n",
    "\n",
    "# true values\n",
    "y_true = X_test['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66f57609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[0.543471 0.368693]\n",
      " [0.052039 0.035797]]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Calculate and output confusion matrix\n",
    "#\n",
    "confusion = confusion_matrix(y_true, y_pred, normalize='all')\n",
    "print(\"Confusion Matrix:\")\n",
    "print(np.array2string(confusion, formatter={'all': lambda x: f'{x:.6f}'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dc1e764",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Now we do Bayesian hyperparameter optimization\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e28ca6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_model_search(ddf):\n",
    "    \n",
    "    # train / test split\n",
    "    X_train, X_test = ddf.random_split([0.8, 0.2], random_state=42)\n",
    "    \n",
    "    # primes vs composites\n",
    "    num_composites = sum(ddf['Label'] == 0)\n",
    "    num_primes     = sum(ddf['Label'] == 1)\n",
    "    print(f'{num_primes} primes and {num_composites} composites out of {len(ddf)} numbers total')\n",
    "\n",
    "    # convert Dask dataframes to DMatrix XGBoost format\n",
    "    dtrain = xgb.DMatrix(X_train.drop(columns=['Label']), X_train['Label'])\n",
    "    dtest = xgb.DMatrix(X_test.drop(columns=['Label']), X_test['Label'])\n",
    "    \n",
    "    # hyperparameter search space\n",
    "    space = {\n",
    "        'max_depth': hp.quniform('max_depth', 2, 16, 1),\n",
    "        'scale_pos_weight': hp.uniform('scale_pos_weight', 0.5, 1),\n",
    "        'learning_rate': hp.loguniform('learning_rate', -4, 0),\n",
    "        'subsample': hp.uniform('subsample', 0.5, 1),\n",
    "        'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1),\n",
    "        'reg_alpha': hp.loguniform('reg_alpha', -5, 2),\n",
    "        'reg_lambda': hp.loguniform('reg_lambda', -5, 2),\n",
    "    }\n",
    "\n",
    "    # objective function to optimize\n",
    "    def objective(params):\n",
    "\n",
    "        params['max_depth'] = int(params['max_depth'])\n",
    "        params['objective'] = 'binary:logistic'\n",
    "        params['eval_metric'] = 'auc'\n",
    "        params['n_jobs'] = -1\n",
    "\n",
    "        # Create DMatrix\n",
    "        dtrain = xgb.DMatrix(X_train.drop(columns=['Label']), X_train['Label'])\n",
    "        dtest = xgb.DMatrix(X_test.drop(columns=['Label']), X_test['Label'])\n",
    "\n",
    "        # Train the model with given hyperparameters\n",
    "        model = xgb.train(params, dtrain, evals=[(dtrain, 'train'), (dtest, 'test')],\n",
    "                          verbose_eval=False, early_stopping_rounds=10)\n",
    "\n",
    "        # Evaluate the model and return the negative AUC-PR as the loss (to minimize)\n",
    "        y_pred_prob = model.predict(dtest)\n",
    "        y_true = X_test['Label']\n",
    "        auc_score = -roc_auc_score(y_true, y_pred_prob)\n",
    "\n",
    "        return auc_score\n",
    "\n",
    "    # use Hyperopt to find the best hyperparameters\n",
    "    best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=50)\n",
    "\n",
    "    # record best hyperparameters\n",
    "    best_max_depth = int(best['max_depth'])\n",
    "    best_learning_rate = best['learning_rate']\n",
    "    best_subsample = best['subsample']\n",
    "    best_colsample_bytree = best['colsample_bytree']\n",
    "    best_reg_alpha = best['reg_alpha']\n",
    "    best_reg_lambda = best['reg_lambda']\n",
    "\n",
    "    # train the best XGBoost model \n",
    "    best_params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'aucpr',\n",
    "        'max_depth': best_max_depth,\n",
    "        'learning_rate': best_learning_rate,\n",
    "        'subsample': best_subsample,\n",
    "        'colsample_bytree': best_colsample_bytree,\n",
    "        'reg_alpha': best_reg_alpha,\n",
    "        'reg_lambda': best_reg_lambda,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "\n",
    "    best_model = xgb.train(best_params, dtrain, evals=[(dtrain, 'train'), (dtest, 'test')],\n",
    "                            verbose_eval=True)\n",
    "\n",
    "    # make predictions with the best model\n",
    "    y_pred_prob_best = best_model.predict(dtest)\n",
    "\n",
    "    # convert probabilities into bits\n",
    "    threshold = y_pred_prob_best.mean()\n",
    "    y_pred = [1 if pred >= threshold else 0 for pred in y_pred_prob_best]\n",
    "\n",
    "    # ground truth\n",
    "    y_true = X_test['Label']\n",
    "\n",
    "    # calculate and output confusion matrix\n",
    "    confusion = confusion_matrix(y_true, y_pred, normalize='all')\n",
    "    print(\"Best Model Confusion Matrix:\")\n",
    "    print(np.array2string(confusion, formatter={'all': lambda x: f'{x:.6f}'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19d286d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23000 primes and 239144 composites out of 262144 numbers total\n",
      "100%|████████| 50/50 [01:01<00:00,  1.24s/trial, best loss: -0.5294763465873017]\n",
      "[0]\ttrain-aucpr:0.09783\ttest-aucpr:0.09873\n",
      "[1]\ttrain-aucpr:0.09843\ttest-aucpr:0.09894\n",
      "[2]\ttrain-aucpr:0.09867\ttest-aucpr:0.09865\n",
      "[3]\ttrain-aucpr:0.09871\ttest-aucpr:0.09878\n",
      "[4]\ttrain-aucpr:0.09895\ttest-aucpr:0.09864\n",
      "[5]\ttrain-aucpr:0.09906\ttest-aucpr:0.09878\n",
      "[6]\ttrain-aucpr:0.09914\ttest-aucpr:0.09883\n",
      "[7]\ttrain-aucpr:0.09919\ttest-aucpr:0.09857\n",
      "[8]\ttrain-aucpr:0.09931\ttest-aucpr:0.09846\n",
      "[9]\ttrain-aucpr:0.09935\ttest-aucpr:0.09840\n",
      "Best Model Confusion Matrix:\n",
      "[[0.638886 0.273278]\n",
      " [0.058209 0.029628]]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Hyperparameter search for 18-bit strings first\n",
    "#\n",
    "best_model_search(ddf_18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "220b2ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# The confusion matrix is composed as C(true_label, predicted_label), so that \n",
    "# C(0,0) are true negatives, \n",
    "# C(0,1) are false positives, \n",
    "# C(1,0) are false negatives,\n",
    "# C(1,1) are true positves.\n",
    "#\n",
    "# The true positive rate is ~ 0.03, which is of course *very* low, but this is exactly what we expected\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9387104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Let's try 24-bit strings\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1a16cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data using Dask\n",
    "ddf_24 = dd.read_csv('binary_data_24.csv', assume_missing=True, dtype={\"BinaryString\": str, \"Label\": int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69ce1dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1077871 primes and 15699345 composites out of 16777216 numbers total\n",
      "100%|███████| 50/50 [3:08:27<00:00, 226.16s/trial, best loss: -0.51854879458775]\n",
      "[0]\ttrain-aucpr:0.06937\ttest-aucpr:0.06941\n",
      "[1]\ttrain-aucpr:0.06939\ttest-aucpr:0.06945\n",
      "[2]\ttrain-aucpr:0.06940\ttest-aucpr:0.06946\n",
      "[3]\ttrain-aucpr:0.06940\ttest-aucpr:0.06946\n",
      "[4]\ttrain-aucpr:0.06941\ttest-aucpr:0.06946\n",
      "[5]\ttrain-aucpr:0.06941\ttest-aucpr:0.06946\n",
      "[6]\ttrain-aucpr:0.06941\ttest-aucpr:0.06946\n",
      "[7]\ttrain-aucpr:0.06941\ttest-aucpr:0.06946\n",
      "[8]\ttrain-aucpr:0.06941\ttest-aucpr:0.06946\n",
      "[9]\ttrain-aucpr:0.06941\ttest-aucpr:0.06947\n",
      "Best Model Confusion Matrix:\n",
      "[[0.635707 0.300054]\n",
      " [0.041912 0.022326]]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Hyperparameter search for 24-bit strings \n",
    "#\n",
    "best_model_search(ddf_24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13164459",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# The true positive rate is ~ 0.02, which is even lower than before\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e494d99f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
